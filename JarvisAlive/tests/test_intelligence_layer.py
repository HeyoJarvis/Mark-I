#!/usr/bin/env python3
"""
Test script for the Intelligence Layer with Human-in-the-Loop workflow orchestration.

This script demonstrates the complete Intelligence Layer functionality including:
- Workflow creation and planning
- AI-powered next step recommendations
- Human-in-the-loop decision points
- Autopilot control and bypass functionality
- Rich interactive interfaces
"""

import asyncio
import os
import logging
from typing import Dict, Any
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Import Intelligence Layer components
from orchestration.intelligence.workflow_brain import WorkflowBrain
from orchestration.intelligence.models import (
    AutoPilotMode, 
    WorkflowStatus, 
    HITLPreferences,
    InteractionStyle
)

# Import existing orchestration for integration
from orchestration.universal_orchestrator import UniversalOrchestratorConfig


class IntelligenceLayerTester:
    """Test harness for Intelligence Layer functionality."""
    
    def __init__(self):
        """Initialize the test environment."""
        self.logger = logging.getLogger(__name__)
        self.workflow_brain: WorkflowBrain = None
        
    async def setup(self):
        """Set up the test environment."""
        self.logger.info("üîß Setting up Intelligence Layer test environment...")
        
        # Get API key
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            self.logger.error("ANTHROPIC_API_KEY not found in environment")
            return False
        
        # Configure WorkflowBrain
        config = {
            'anthropic_api_key': api_key,
            'redis_url': 'redis://localhost:6379'  # Default Redis port
        }
        
        try:
            # Initialize WorkflowBrain
            self.workflow_brain = WorkflowBrain(config)
            
            # Initialize orchestration integration
            await self.workflow_brain.initialize_orchestration()
            
            self.logger.info("‚úÖ Intelligence Layer test environment ready")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to setup test environment: {e}")
            return False
    
    async def test_basic_workflow_creation(self):
        """Test basic workflow creation and planning."""
        self.logger.info("\nüß™ TEST 1: Basic Workflow Creation")
        
        try:
            # Create a business creation workflow
            workflow_id = await self.workflow_brain.create_workflow(
                user_id="test_user_123",
                session_id="test_session_456",
                workflow_type="business_creation",
                initial_request="Create a sustainable coffee subscription business",
                context={
                    "user_preferences": {"industry": "food_beverage", "sustainability_focus": True},
                    "budget_range": "startup"
                }
            )
            
            # Verify workflow was created
            if workflow_id in self.workflow_brain.active_workflows:
                workflow_state = self.workflow_brain.active_workflows[workflow_id]
                
                self.logger.info(f"‚úÖ Workflow created successfully: {workflow_id}")
                self.logger.info(f"   Title: {workflow_state.workflow_title}")
                self.logger.info(f"   Type: {workflow_state.workflow_type}")
                self.logger.info(f"   Planned Steps: {len(workflow_state.pending_steps)}")
                self.logger.info(f"   Status: {workflow_state.status.value}")
                
                return workflow_id
            else:
                self.logger.error("‚ùå Workflow not found in active workflows")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Workflow creation failed: {e}")
            return None
    
    async def test_ai_recommendations(self, workflow_id: str):
        """Test AI-powered next step recommendations."""
        self.logger.info(f"\nüß™ TEST 2: AI Recommendations Generation")
        
        try:
            workflow_state = self.workflow_brain.active_workflows[workflow_id]
            
            # Generate AI recommendations
            recommendations = await self.workflow_brain._generate_next_step_recommendations(workflow_state)
            
            if recommendations:
                self.logger.info(f"‚úÖ Generated {len(recommendations)} AI recommendations:")
                
                for i, rec in enumerate(recommendations, 1):
                    self.logger.info(f"   {i}. {rec.description}")
                    self.logger.info(f"      Agent: {rec.agent_id}")
                    self.logger.info(f"      Confidence: {rec.confidence_score:.1%}")
                    self.logger.info(f"      Time: ~{rec.estimated_time_minutes}min")
                    self.logger.info(f"      Risk: {rec.risk_level.value}")
                    if rec.reasoning:
                        self.logger.info(f"      Reasoning: {rec.reasoning}")
                    self.logger.info("")
                
                return recommendations
            else:
                self.logger.warning("‚ö†Ô∏è No AI recommendations generated")
                return []
                
        except Exception as e:
            self.logger.error(f"‚ùå AI recommendation generation failed: {e}")
            return []
    
    async def test_autopilot_modes(self, workflow_id: str, recommendations):
        """Test different autopilot modes and decision logic."""
        self.logger.info(f"\nüß™ TEST 3: AutoPilot Modes Testing")
        
        workflow_state = self.workflow_brain.active_workflows[workflow_id]
        
        try:
            # Test different autopilot modes
            modes_to_test = [
                AutoPilotMode.HUMAN_CONTROL,
                AutoPilotMode.SMART_AUTO,
                AutoPilotMode.FULL_AUTO,
                AutoPilotMode.CUSTOM_THRESHOLD
            ]
            
            for mode in modes_to_test:
                self.logger.info(f"   Testing {mode.value} mode...")
                
                # Update workflow autopilot mode
                original_mode = workflow_state.autopilot_mode
                workflow_state.autopilot_mode = mode
                
                # Evaluate autopilot decision
                autopilot_decision = await self.workflow_brain.autopilot_manager.evaluate_autopilot_decision(
                    workflow_state, 
                    recommendations
                )
                
                self.logger.info(f"      Should proceed automatically: {autopilot_decision.should_proceed_automatically}")
                self.logger.info(f"      Reasoning: {autopilot_decision.reasoning}")
                if autopilot_decision.chosen_option:
                    self.logger.info(f"      Chosen option: {autopilot_decision.chosen_option.description}")
                
                # Restore original mode
                workflow_state.autopilot_mode = original_mode
            
            self.logger.info("‚úÖ AutoPilot modes testing completed")
            
        except Exception as e:
            self.logger.error(f"‚ùå AutoPilot testing failed: {e}")
    
    async def test_human_decision_processing(self, workflow_id: str, recommendations):
        """Test human decision processing with simulated inputs."""
        self.logger.info(f"\nüß™ TEST 4: Human Decision Processing")
        
        workflow_state = self.workflow_brain.active_workflows[workflow_id]
        
        try:
            # Test different types of human decisions
            test_decisions = [
                {
                    "choice": "option_1",
                    "description": "Choose first AI recommendation"
                },
                {
                    "choice": "custom:I want to conduct competitor analysis first",
                    "description": "Custom user input"
                },
                {
                    "choice": "pause",
                    "description": "Pause workflow"
                }
            ]
            
            for test_case in test_decisions:
                self.logger.info(f"   Testing: {test_case['description']}")
                
                # Create simulated human decision
                from orchestration.intelligence.models import HumanDecision
                
                human_decision = HumanDecision(
                    decision_id="",
                    workflow_id=workflow_id,
                    workflow_step=workflow_state.current_step_index,
                    ai_recommendations=recommendations,
                    human_choice=test_case['choice'],
                    custom_input=test_case['choice'].split(':', 1)[1] if test_case['choice'].startswith('custom:') else None,
                    reasoning=f"Test decision: {test_case['description']}"
                )
                
                # Process human decision
                workflow_step = await self.workflow_brain.decision_engine.process_human_decision(
                    human_decision,
                    recommendations,
                    workflow_state
                )
                
                self.logger.info(f"      ‚úÖ Processed: {workflow_step.description}")
                self.logger.info(f"      Agent: {workflow_step.agent_id}")
                self.logger.info(f"      Status: {workflow_step.status.value}")
                self.logger.info("")
            
            self.logger.info("‚úÖ Human decision processing tests completed")
            
        except Exception as e:
            self.logger.error(f"‚ùå Human decision processing failed: {e}")
    
    async def test_workflow_execution_simulation(self, workflow_id: str):
        """Test simulated workflow execution (without actual agent calls)."""
        self.logger.info(f"\nüß™ TEST 5: Workflow Execution Simulation")
        
        try:
            workflow_state = self.workflow_brain.active_workflows[workflow_id]
            
            # Enable full autopilot for automated execution
            workflow_state.autopilot_mode = AutoPilotMode.FULL_AUTO
            
            self.logger.info(f"   Starting execution simulation for workflow: {workflow_state.workflow_title}")
            self.logger.info(f"   Mode: {workflow_state.autopilot_mode.value}")
            
            # Mock the orchestrator to avoid actual agent calls
            original_orchestrator = self.workflow_brain.universal_orchestrator
            self.workflow_brain.universal_orchestrator = None  # Disable actual orchestrator
            
            # Simulate a few execution steps
            step_count = 0
            max_simulation_steps = 3
            
            while (workflow_state.is_active and 
                   not workflow_state.emergency_pause and 
                   step_count < max_simulation_steps):
                
                self.logger.info(f"   Executing simulation step {step_count + 1}...")
                
                # Execute next step (will use system fallbacks)
                step_result = await self.workflow_brain._execute_next_step(workflow_state)
                
                if step_result.has_error:
                    self.logger.info(f"      Step completed with expected simulation result")
                    break
                elif step_result.requires_human_input:
                    self.logger.info(f"      Step requires human input (as expected)")
                    break
                
                step_count += 1
            
            # Restore orchestrator
            self.workflow_brain.universal_orchestrator = original_orchestrator
            
            self.logger.info(f"‚úÖ Workflow execution simulation completed ({step_count} steps)")
            self.logger.info(f"   Final status: {workflow_state.status.value}")
            self.logger.info(f"   Completed steps: {len(workflow_state.completed_steps)}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Workflow execution simulation failed: {e}")
    
    async def test_workflow_state_management(self, workflow_id: str):
        """Test workflow state management and persistence."""
        self.logger.info(f"\nüß™ TEST 6: Workflow State Management")
        
        try:
            workflow_state = self.workflow_brain.active_workflows[workflow_id]
            
            # Test state updates
            original_context = workflow_state.current_context.copy()
            
            # Update context
            test_data = {
                "market_research": {"market_size": "$1.2B", "growth_rate": "15%"},
                "competitive_analysis": {"main_competitors": ["CompetitorA", "CompetitorB"]},
                "brand_concept": {"name": "TestBrand", "tagline": "Innovation First"}
            }
            
            workflow_state.update_context(test_data)
            
            # Verify context updates
            for key, value in test_data.items():
                if key in workflow_state.accumulated_data:
                    self.logger.info(f"   ‚úÖ Context updated: {key}")
                else:
                    self.logger.warning(f"   ‚ö†Ô∏è Context missing: {key}")
            
            # Test progress calculation
            progress = workflow_state.progress_percentage
            self.logger.info(f"   Progress: {progress:.1f}%")
            
            # Test duration calculation
            duration = workflow_state.duration_seconds
            self.logger.info(f"   Duration: {duration:.1f} seconds")
            
            # Test workflow properties
            self.logger.info(f"   Is active: {workflow_state.is_active}")
            self.logger.info(f"   Needs human input: {workflow_state.needs_human_input}")
            
            self.logger.info("‚úÖ Workflow state management tests completed")
            
        except Exception as e:
            self.logger.error(f"‚ùå Workflow state management failed: {e}")
    
    async def run_comprehensive_test(self):
        """Run comprehensive Intelligence Layer test suite."""
        self.logger.info("üöÄ Starting Intelligence Layer Comprehensive Tests")
        self.logger.info("=" * 60)
        
        # Setup test environment
        setup_success = await self.setup()
        if not setup_success:
            return False
        
        # Run test sequence
        workflow_id = await self.test_basic_workflow_creation()
        if not workflow_id:
            return False
        
        recommendations = await self.test_ai_recommendations(workflow_id)
        if not recommendations:
            return False
        
        await self.test_autopilot_modes(workflow_id, recommendations)
        await self.test_human_decision_processing(workflow_id, recommendations)
        await self.test_workflow_execution_simulation(workflow_id)
        await self.test_workflow_state_management(workflow_id)
        
        # Final summary
        self.logger.info("\n" + "=" * 60)
        self.logger.info("üéâ Intelligence Layer Comprehensive Tests COMPLETED")
        
        workflow_state = self.workflow_brain.active_workflows[workflow_id]
        self.logger.info(f"   Final workflow status: {workflow_state.status.value}")
        self.logger.info(f"   Human decisions recorded: {len(workflow_state.human_decisions)}")
        self.logger.info(f"   Context data accumulated: {len(workflow_state.accumulated_data)} items")
        self.logger.info(f"   Total test duration: {workflow_state.duration_seconds:.1f} seconds")
        
        return True


async def main():
    """Main test execution function."""
    print("üß† Intelligence Layer Test Suite")
    print("Testing Human-in-the-Loop workflow orchestration...")
    print()
    
    tester = IntelligenceLayerTester()
    
    try:
        success = await tester.run_comprehensive_test()
        
        if success:
            print("\n‚úÖ ALL TESTS PASSED - Intelligence Layer is ready for production use!")
            print("\nNext steps:")
            print("1. Integrate WorkflowBrain with main.py")
            print("2. Add workflow persistence with Redis")
            print("3. Create workflow templates for common use cases")
            print("4. Implement learning engine for continuous improvement")
            
        else:
            print("\n‚ùå TESTS FAILED - Please review the logs and fix issues")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Tests interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Test execution failed: {e}")
        logging.exception("Test execution error")


if __name__ == "__main__":
    # Ensure we're in the correct directory
    if not os.path.exists("orchestration/intelligence"):
        print("‚ùå Please run this test from the JarvisAlive directory")
        exit(1)
    
    asyncio.run(main())